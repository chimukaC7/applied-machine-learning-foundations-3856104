Using MLFlow
Selecting transcript lines in this section will navigate to timestamp in the video
Now let's talk about deployment. We're going to use a tool called MLFlow to do that. And MLFlow has a bunch of features. I'm not going to show all of them here, but I'm going to show how you can easily create a model and persist it. If you've got your code working, how we just showed in the last video, it should be really easy to use MLFlow. Let's import MLFlow. Okay. That looks like that executed. Let's check out our version, and we're using version 2.11.3. Just be aware that there could be some changes that make things behave differently. But for this version, we're using 2.11. Now, the cool thing that I can do is I can come in here and I can say, with MLFlow, I can persist a model. And remember, up above we have this lr_pipe. It includes a bunch of code to take our raw data, clean it up, have transformations for numeric values, have transformations for categorical values. The whole pipeline's in there and the final model is in there as well. I'm going to call this log_model function here, and we're going to persist this using MLFlow. Let's run that. Okay. After that's executed, we should have this model_info object. You can inspect that. One of the things that you'll want to be aware of is an attribute called artifact path. And this is where it has persisted your output. I'm going to use this command down here, !tree. Note that this is not a Python command, it's not markdown, it's not a cell magic. In Jupyter, when you precede a command with an exclamation point, it's going to run on the system. In this case, we are running in Codespaces, which is a Linux server. So tree is a Linux command. If you were to be running this locally on a Windows Box, tree would not be found. So just be aware of that. I'm just showing that to show the artifacts of what's going on here. We said lr_pipe down here, and if you look in the directory structure, we have this mlruns folder here. And inside of that, we have an artifacts and we have lr_pipe. And this is a bundle that represents our model, the whole pipeline. Another thing that we might want to look at is this run ID. You can run multiple models and track them. So this looks like it starts with a91. If we go up here, you can see that there's a91. You could make multiple models and each of those would be persisted separately. Once I have that, all I have to do to load my model is use this function, load_model. I give it the path to the artifact that I want to run. Let's run that. This should instantiate a model. Let's just inspect the model object so that this is an MLFlow model object. But look at this. I can say predict and I can pass in data and get a prediction from this. This might seem simple, but this is really cool. I have taken a bunch of complicated code and I'm using MLFlow's ability to persist this, but also to create a model from this. Now this is just scratching the surface of what MLFlow can do. Some other cool things that MLFlow can do is it can start a web service to serve this same model. It can also create a docker build and include all of the dependencies, so that you can deploy a docker build with a web service for this model as well. MLFlow is a great tool to go beyond notebooks and deploy your model.


Imagine you've just built a fantastic Lego model, and now you want to show it off and make sure you can rebuild it exactly the same way in the future. MLFlow is like a special box for your Lego model that not only stores it safely but also keeps the instructions and pieces organized.

In the “Using MLFlow” video, it's explained that MLFlow helps you take the machine learning models you've created and makes them easy to use again in the future, share with others, or even turn into a live application. Here's how it works:

Storing Your Model: Just like saving your Lego model in a box, MLFlow lets you save your machine learning model. This includes all the steps it took to clean your data and make predictions.

Keeping Instructions: MLFlow remembers how your model was built, including all the data transformations and the model itself, similar to keeping the Lego instructions safe.

Sharing and Reusing: If you want to show your model to someone else or use it again, MLFlow makes this easy. It's like giving someone your special box, and they can rebuild the Lego model without any hassle.

Deployment: Finally, MLFlow can help turn your model into a live application, just like displaying your Lego model for everyone to see. It can even package everything needed into a container (like a bigger box) so it can run anywhere.


So, MLFlow is a tool that helps manage your machine learning projects from start to finish, making it easier to save, share, and deploy your models.



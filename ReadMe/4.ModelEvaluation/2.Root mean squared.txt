Root mean squared
Selecting transcript lines in this section will navigate to timestamp in the video
Let's talk about some other metrics that might be important. The Scikit-Learn, I keep saying this, but one of the reasons I like Scikit-Learn is that it has a consistent interface, and it has a module called metrics, and in that module are a bunch of different metrics that you can leverage. And they all have the same interface. So you can import these metrics and you can run them. A common metric for a regression model is mean squared error. So let's run this. This is a little bit different than the score method. With the score method, you pass in an x_test and a y_test. With the metrics functions that we're going to import here, you pass in a true y and the predictions from y. So what this is telling me is that our mean squared error, if you take all the errors of all of these test cases and you square them, you have this value right here. And it's kind of hard for me to tell what this is. It's like $14 billion squared. So confusing thing about this is that this is in terms of what we're predicting, in this case, dollars, but this is dollar squared. Not quite sure what dollar squared are. If that's like wallpaper that you put on your wall with dollars. But this is a metric that lets you understand how your model is doing. And you can quantify how far off it is. But you can also see if a model has a lower mean squared error, then it performs better than one with a higher error. Now you might ask why is it squaring the error? Why doesn't it just take the average of all the errors? And the reason is, you might have some errors where you predict low and other errors where you predict high. If you're just to take the average of those, it is possible for those to cancel each other out. And even though you might have large errors because they're canceling each other out, this might come up to a low value. So in order to prevent them from canceling each other out, one of the ways that you can do that is to square the errors. Now we can ask it not to square the output. And we can say squared is equal to false. If we do that, we get this result here, which is $120,000. That gives me more of a gut feel about what's going on with my model. Again, these are housing prices around the Seattle area, and it looks like a lot of those houses can be pretty expensive. So an error of $120,000 for a four million-dollar house may or may not be important for my business case. Okay. Another metric that we can use is the mean absolute error. So this solves that issue of errors canceling each other out by just taking the absolute value of all of those. And if we do that, we can see that this value is $64,000. One of the things that we might want to do is compare this to a different model. And again, this is easy with Scikit-Learn, we just swap out the model that we're comparing it to. Now I believe this is going to fail because remember I just restarted my notebook here. So let's run this and let's see if it fails. It did fail. It's saying name error, name means it's looking for lr_pipe and it can't find it. So I'll quickly come up here and run that lr_pipe code. That should be this one right here. There is lr_pipe. Let me just reload that and we'll come down here. Now we can compare two models, and we can see that our CatBoost model is off by $64,000, whereas our linear regression model is off by $98,000. This makes it a lot easier to quantify how our models are performing. So remember that we have this metrics module, and you can use that to calculate other metrics in addition to the coefficient of determination.


The “Root mean squared” video discusses a way to measure how well a machine learning model predicts outcomes, specifically for things like predicting house prices. Let's simplify this:

Imagine you're throwing darts at a dartboard, where the bullseye represents the actual price of a house. Each dart you throw lands somewhere on the board - this represents your model's guess at the house price. Sometimes you'll be close to the bullseye (accurate guess), and sometimes you'll be far away (inaccurate guess).

Mean Squared Error (MSE) is like calculating the average distance each dart is from the bullseye, but with a twist: before averaging, you square each distance. Squaring makes sure we treat all misses equally, whether they're above or below the bullseye, and it really penalizes the darts that are far off.

However, MSE gives us a number that's hard to make sense of because it's not in the same units as house prices anymore (it's in “squared dollars”). That's where Root Mean Squared Error (RMSE) comes in. Taking the square root of MSE converts it back to regular dollars, making it easier to understand. If RMSE is $120,000, it means your model's guesses are, on average, $120,000 away from the actual house prices.

The video also mentions Mean Absolute Error (MAE), another way to measure accuracy. MAE is like calculating the average distance of each dart from the bullseye without squaring them. It's more straightforward than MSE because it stays in the same units (dollars), making it easier to interpret. If MAE is $64,000, your guesses are, on average, $64,000 off from the real prices.

In summary, these measurements help us understand how good or bad our model is at predicting house prices. MSE and RMSE focus on penalizing big mistakes heavily, while MAE gives a more direct average error in dollars.

